export const text = `Observing brain activity while a person watches a movie is helping filmmakers produce more effective movie trailers. Daily Life is full of decisions—some big and some small. How does the mind reach a decision? Psychologists have learned a great deal about the processes involved in reaching a decision and have identified many steps we can take to improve our decision making. Zooming in, we can use imaging technologies to observe how the brain reacts to a number of choices. For example, do you really want to see that movie based on its trailer? Film producers are using brain imaging when editing movie trailers to elicit the reactions they want from an audience (Randall, 2011). They have only a few seconds to convince the audience to see their film. Assuming that the film’s ability to elicit emotion drives the decision to see it, filmmakers remove the parts of a trailer that produce neutral emotional responses and splice together the most dramatic parts. Is this practice scientifically valid? It may be useful in some cases. In Chapter 7, we discussed how emotions range along a continuum. Some emotions, such as fear, are associated with precise physical responses, while others, such as pride, are associated with more ambiguous physical responses. You could probably develop a movie trailer that would evoke fear in viewers, but eliciting more complex emotions might be more difficult. Zooming out to the moviegoers’ decision to see a movie, what factors aside from seeing an emotional trailer might influence their choice? Individual differences play key roles. One person might enjoy horror films, while another does not. Using the social perspective to zoom out still farther, we can see that people respond to horror films based on their beliefs about the expectations of others. You might think that males are predisposed to like horror films and females to like chick flicks, but psychology is rarely that simple. Instead, a person’s reaction to horror films is strongly determined by social attitudes and beliefs about how same- and opposite-sex peers would respond to the film (Mundorf, Weaver, & Zillmann, 1989). The mind uses symbols or mental representations to signify information, just icons represent some of your favorite social networks, such as Facebook, Twitter, Instagram, and Snapchat. In this chapter, we will explore how we use the tools of language and intelligence to think, which in turn guides our behavior. Beginning with the parts of the brain that process information, we will zoom out to the individual differences of personality and experience and farther still to the social and larger cultural contexts that shape the way we think. The word cognitioncognitionInternal mental processes including information processing, thinking, reasoning, and problem solving.            cognition        Internal mental processes including information processing, thinking, reasoning, and problem solving.            , as in the term cognitive psychology, is derived from the Latin cogito, which literally means to think. Thinking allows us to manipulate information internally to construct models of the world, plan our interactions with that world, and regulate ourselves to meet our goals. As you will see, cognitive psychology covers a broad area of topics. In addition to perception, learning, and memory, which we discussed in previous chapters, cognitive psychology addresses questions of thinking, language, and intelligence. We think about what we know. In the broadest sense of the word, knowledge is the entire body of information acquired through study, investigation, observation, and experience. To manage this large collection of knowledge, the mind uses symbols, or mental representations, to signify information. Using mental representations is similar to having an icon on your computer desktop that represents Microsoft Word and a profile photograph on Facebook that represents your best friend. The most familiar uses of mental representations are found in language, both written and spoken. Depending on the language you choose, you could represent the animal coming toward you on the sidewalk as a hund (German), chien (French), gau (Chinese), perro (Spanish), or dog (English). Representations can be visual too. For example, you could snap a photo or sketch a picture of the dog. Despite the differences in these two visual representations, the dog that each portrays is the same. We can view the representation of the dog (the sound or the appearance of the word used, the patterns of light in your photo or drawing) as a vehicle for carrying information about the content of our knowledge of this dog (it seems to be a friendly, young golden retriever). In this chapter, we explore the ability of minds to form mental representations and manipulate them to make sense of the world. What forms can representations take? What are the relationships between the representations and the content they symbolize? Temple Grandin, a college professor with autism spectrum disorder, describes her way of thinking as thinking in pictures (Grandin, 2010). Albert Einstein is also widely quoted as relying on mental visualization in the early stages of his thinking and only later putting his ideas into words (Einstein, 1945). To what extent do the rest of us think in mental images? By mental image, we are referring to a representation of any sensory experience that is stored in memory and can be retrieved for use later. For example, you can call up a visual image of your first car, picture the letters of your name, or silently hum the first bars of Happy Birthday to yourself quite easily. People treat mental images much like they would a real object (Kosslyn, 1978,  1980,  1994). We can turn visual mental images around in our minds, zoom in or out, and identify their features (see Figure 10.1). If you were to think about a map of the United States (assuming you have a good grasp of geography), it would take you longer to mentally count the major cities between Los Angeles and New York than those between Chicago and New York, just as it would if you were looking at a real map. A person familiar with New York City could follow a mental route among these buildings, zoom in or out, and identify important features like landmarks and a favorite place to have coffee. Children are particularly likely to use visual images in their thinking. In one study, between 2 and 15% of elementary school children experienced long-lasting and detailed visual images of a complex picture they viewed for a short interval (Haber & Haber, 1964). The children described the scene using the present tense, suggesting that they were scanning a mental replica. Except for rare cases like Grandin, few adults can do this. It is possible that language becomes an increasingly important way to organize thinking during childhood and might begin to overwrite or interfere with the ability to directly access visual images. Temple Grandin, a college professor with autism spectrum disorder, is shown here with actress Claire Danes, who portrayed her in a 2010 made-for-television movie. Grandin has described her cognitive experience as thinking in pictures. It is likely that young children depend on a similar approach to thinking, but learning language provides new dimension to our ability to think. Regardless of the exact form taken by mental representations, our knowledge would be useless unless we imposed some type of organization on all the bits we know. To supply this organization, we extract special, organizing ideas known as conceptsconceptsAn organizing principle derived from experience.            concepts        An organizing principle derived from experience.             from the specific instances and occurrences we experience. Concept formation is not unique to humans. Nonhuman animals as diverse as pigeons and monkeys demonstrate concept formation (Herrnstein, 1979). In one study, pigeons learned to peck at projected images of water with fish to obtain food rewards but to withhold pecking at images of water without fish (Herrnstein & de Villiers, 1980). Subsequently, a new set of slides was presented. The pigeons successfully distinguished between the fish and the nonfish slides, even though they had not seen these particular images during their prior training. The pigeons appeared to have extracted a fish concept from their experience. What does it mean to have a fish or any other type of concept? How are we (and pigeons) able to construct a new concept? Because of the memory processes discussed in Chapter 9, you already know what a dog is. If you were asked to feed your neighbor’s dog while your neighbor goes on vacation, you could locate the correct animal, provide dog food instead of cat food, and exercise appropriate caution if your neighbor’s dog is unfriendly. This activity sounds simple, but what if you recruited an alien from another planet to help you with your task? What information about dogs would the alien need to know to succeed? Essentially, what you must convey to your alien friend is the concept of dog (see Table 10.1). ApproachApplication to dog categoryDisadvantagesDictionary definitionDescribe a dog as a domesticated carnivorous mammal (Canis familiaris) related to the foxes and wolves and raised in a wide variety of breeds. Gives more information than needed to classify a dog correctly. Common featuresDescribe dogs as furry animals with four legs that bark and wag their tails. Results in too many exceptions (e.g., Chihuahuas are not furry). Overlapping featuresCompare features of a suspected dog with features of the dog concept. Lacks precise boundaries for most categories (e.g., tastes good might be a category feature for dogs in some cultures but not in others). PrototypeAverage all members of the dog category. Does not provide a good way to think about a category’s variability. ExemplarUse a specific instance of a category a model. Excludes some category members that are too dissimilar to model. You might start the discussion with a dictionary definition of dog. In the dictionary, you find that a dog is a domesticated carnivorous mammal (Canis familiaris) related to the foxes and wolves and raised in a wide variety of breeds. This definition seems rather remote from what we know to be a dog. You don’t need to know what dogs eat and who their nearest relatives are to identify one correctly. London-based artist Stephen Wiltshire, who like Temple Grandin has autism spectrum disorder, has been described as a human camera. Wiltshire can fly over a major city such as New York in a helicopter for about 1 hour and then recreate highly accurate and detailed drawings of the city. His talent is an extreme and unusual form of the use of visual imagery. Perhaps you could find some common features of dogs that would allow you to distinguish between dogs and nondogs. You could tell your alien friend that dogs are furry animals with four legs that bark and wag their tails. Unfortunately, this system has a logical flaw (Wittgenstein, 1953). No matter how careful your definition, even for the simplest concepts, somebody will think of an exception. Although we can agree that all dogs are animals, this feature alone is insufficient for distinguishing dogs from cats and raccoons. Having fur does not describe some chihuahuas, and basenjis don’t bark. A dog that has lost a leg in an accident no longer has four legs. Most dogs we know wag their tails, but there may be an abused dog that keeps its tail perpetually between its legs, as well as dogs that have tails too stubby to wag. To resolve this dilemma, you can make your definition more flexible. Instead of being rigidly defined by a checklist of features, a concept could describe a group of instances that share overlapping features. This approach is similar to a feature detection model (Smith, Shoben, & Rips, 1974). According to this type of model, people determine the truthfulness of statements like a canary is a bird by considering overlapping features (wings, beak, flies, and chirps). Using this approach, the alien could compare the features of an animal suspected of being a dog with a checklist of dog features. This approach has problems, too. Some categories are clear, such as triangles, but others do not have precise enough boundaries for the checklist approach to work. People in some cultures would list taste good as a feature of dogs, but Americans probably would not. In addition, the feature checklist approach doesn’t seem to match personal experience with thinking. When you think about a dog, do you access a mental checklist of dog features? An alternate approach to thinking about concepts is to consider some type of standard dog, or a prototypeprototypeA representation of a category formed by averaging all members of the category.            prototype        A representation of a category formed by averaging all members of the category.             that represents your entire category (Rosch, 1973,  1983). A prototype results from an averaging of all members of your category, and it may not even resemble a real instance (Posner & Keele, 1970). For example, the prototypical dog has an average size, an average tail, average ears, average coloring, and so on. When thinking about a category, you might also retrieve a specific instance of a concept or an exemplarexemplarA specific member of a category used to represent the category            exemplar        A specific member of a category used to represent the category            . This could be the dog that you raised during your childhood or a dog featured in your favorite movie. Pigeons appear to be able to form concepts, such as people and nonpeople. If their pecking is reinforced with food in the presence of an image containing people but not in the presence of images without people, they will learn to peck only when the people images are present. The experimenters used hundreds of images that showed people but varied in number, distance from the camera, age, ethnicity, and other features, but the pigeons still responded appropriately. The processes in which prototypes and exemplars are used are quite similar. Whichever standard you choose, you compare new instances to it to get a sense of fit. The more similar the new objects are to the standard, the more likely you are to include them in your concept. Both approaches are also able to account for the tendency of people to rate apples as more typical fruits than avocados or robins as more typical birds than penguins (Malt & Smith, 1984). Apples are not only closer to the average fruit than avocados are, but they are also more likely to be chosen as an exemplar fruit because of the extensive experience most people have with apples, at least in the United States. Despite the similarities between the prototype and the exemplar approaches, exemplars have some advantages. Compared to prototypes, exemplars provide a better way of thinking about the variability of a category (Rips & Collins, 1993). Averages, which characterize prototypes, do not provide much information about the range of features found in a category. For example, imagine that you just met Joe Kovacs, who tells you that he is an athlete. Judging from Kovac’s imposing physical appearance (he weighs 295 pounds), he seems more similar to your prototypical NFL football player than what he is—a star track-and-field athlete. In contrast, while your personal exemplar for a track-and-field athlete might be a sprinter or distance runner instead of a shot-putter like Kovacs, the individual instances that you know can help you comprehend the variability found within the concept. Although correct, this dictionary definition of a dog might not help you figure out whether an animal standing in front of you is a dog or not. Just when you are feeling comfortable about using prototypes and exemplars to solve your alien’s dog problem, you run into an additional dilemma. The use of prototypes and exemplars rests on similarity. Similar objects will be included in a concept, and dissimilar objects will be excluded. What if your new friend comes across a lifelike dog robot? In many ways, the robot looks and acts like your prototype and exemplar dogs, yet you know it is not a dog. What if you find an unfortunate dog that has been killed on the highway? It hardly retains much similarity to the prototype and exemplar dogs, yet nobody, except perhaps the alien, would question its identity as a dog. Clearly, you need more than prototypes and exemplars to solve your problem. Concept formation can be a type of theory building. In Chapter 2, we defined theories as sets of facts and relationships between facts that can be used to explain and predict phenomena. This definition can also apply to a concept. Like theories, concepts can guide our thinking and be continually tested for accuracy against new, incoming information. Also like theories, concepts do not exist in isolation. As we mentioned in Chapter 9, concepts can be viewed as part of a vast, interconnected network of memories. Thinking about concepts as theories provides insight into the problem of judging category membership, such as deciding whether an avocado is a fruit. Prototypes and exemplars provide a useful starting place for judging category membership. We test our theory that the new item (avocado) fits the category by comparing it to the prototypes (average fruit) and exemplars (apple) of a concept (fruit). We might make the occasional mistake, such as including bats or excluding ostriches in a concept of bird, but most of the time, we will be successful and fast. Using common features to identify dogs, such as has hair or has four legs, would exclude these two: a dog with three legs and an American hairless terrier. This approach also has the advantage of being consistent with observations of how children acquire new concepts, which we explore in Chapter 11. A child might start with a prototype or exemplar dog based on the family pet, possibly overapplying the concept to other four-legged animals at the zoo and failing to apply it to dogs of different breeds. With the help of feedback from others (No, that’s a tiger, not a dog or Yes, a Chihuahua is a dog), the concept becomes more refined. Your alien friend is likely to need the same type of feedback from you when attempting to apply the newly learned concept of dog to a variety of animals. Our dog concept is embedded in a rich, complex set of beliefs and expectations about dogs, animals, nature, and personal experience known as a schema, which we discussed in Chapter 9. This type of schema not only shapes memory storage and retrieval of information relevant to dogs but also allows us to predict new facts about them. If our schema includes likes to play ball, we know that playing ball with a friend’s new dog is likely to be successful. Under what circumstances do people apply a schema to new information? Again, comparisons to typical members of a category appear to play a role. People who are told a new fact about a typical instance of a category are more willing to extend the new fact to all members of a category, whereas a new fact about an atypical category member is less likely to be widely applied (Rips, 1975). For example, if you learn about a new fruit disease found in apples (an exemplar fruit for many people), you are more likely to think other fruits are vulnerable than if you learn that the disease targets a less typical member of the fruit category, such as olives or avocados. Apples are more likely than avocados to be a person’s exemplar fruit because of the extensive experience we have with apples in the United States. Can we find brain activity that correlates with thinking about a particular concept? In Chapter 9, we described imaging studies that identified different patterns of brain activity when people thought about animals or tools (Martin, Wiggs, Ungerleider, & Haxby, 1996). When asked to name animals, the participants showed activation in the visual cortex, suggesting that they would need to think about what a zebra looks like to name it correctly. Naming tools, in contrast, was accompanied by activation in frontal and parietal lobe areas associated with movement, implying that it is helpful to think about what to do with a screwdriver when attempting to name it correctly. You might mistakenly put Olympic shot-putter Joe Kovacs in your category of NFL football player because of his appearance, which is closer to the prototypical football player than it is to the prototypical track-and-field athlete. Using exemplars instead of prototypes to guide the use of concepts helps us think about the variability of a category. This specialization in the brain for processing different types of concepts is supported by observations of patients with brain damage. Some patients have specific difficulties naming pictures of animals, although they can successfully name other living things, such as fruits and vegetables, and nonliving things, such as tools and furniture (Mahon & Caramazza, 2009). Not only do these people have difficulty naming animals, but they also struggle to answer questions about animals, such as Does a whale have legs? Similar questions about nonliving things do not cause difficulty. Others demonstrate the opposite pattern. They are able to name living things but struggle to name nonliving things (Mahon & Caramazza, 2011; see Figure 10.2). These observations suggest that our brains are predisposed to distinguish between living and nonliving things. If forming concepts helps to organize appropriate responses, our ancestors’ ability to form some concepts quickly might have conferred a significant survival advantage. Some individuals with brain damage have difficulty processing certain types of semantic information. The pattern of these deficits varies depending on the location of the damage. For example, patient CW can name living things better than nonliving things, while patient RC names nonliving things better than living things. However, the categories that are affected in this way are relatively few: animals, fruits and vegetables, nonliving things, and members of our own species. This suggests that our brains have been shaped through natural selection to form certain types of categories. Even when a prototype is well understood, such as the signs and symptoms of a disease, evidence suggests that exemplars might work better. Physicians diagnosing cancer who had recently seen similar cases (exemplars) made more accurate diagnoses than those who had not (Brooks, 1990; Brooks, Norman, & Allen, 1991). Amyotrophic lateral sclerosis (ALS, or Lou Gehrig’s disease) is primarily a movement disorder, but the condition also affects a person’s ability to form new concepts. Performance by ALS patients on a concept formation task was correlated with the extent of gray matter loss they had experienced in the left prefrontal and parietal cortices (Libon et al., 2012). Although individual cases vary widely, current diagnostic criteria for ALS have been updated to incorporate features of frontotemporal dementia, a collection of symptoms associated with neural loss in the frontal and temporal lobes that includes deficits in cognition, language, and memory (Strong et al., 2016). Prototypes and exemplars depend on similarity, which can result in similar items, such as this robotic dog, being included in our dog category. It is unlikely that this toddler has vocabulary words for many of the animals seen for the first time in a zoo. Theories of what kind of animal this is will be shaped with the help of the child’s parents. Thinking helps us deal with the many types of problems we face daily. Whether you are figuring out how to manage a busy schedule, help a friend who is feeling blue, or complete your calculus homework, a problemproblemA situation in which a current state is separated from an ideal state by obstacles.            problem        A situation in which a current state is separated from an ideal state by obstacles.             exists whenever there is a difference between where you are and where you would like to be (Newell & Simon, 1972). For example, when you step on the bathroom scale after the holidays, the weight shown on the scale might be different from the ideal weight for your health and appearance; you now have a problem. In addition, referring to a situation as a problem implies that obstacles exist. Returning to your preholiday weight can be challenging. Problems can be well defined or ill defined. Well-defined problems have a solution that can be verified as correct or incorrect, like an algebra problem, whereas ill-defined problems have solutions that are evaluated subjectively (Le, Loll, & Pinkwart, 2013). Our weight-loss problem is well defined because it is easy to verify whether you lose the newly gained weight or not, but many problems in everyday life are ill defined. Thinking that you need to improve your appearance would be an example of an ill-defined problem. People might not agree about what makes another person more attractive. Problem solvingProblem solvingSee also Decision-making            Problem solving        See also Decision-making             is defined as the use of information to meet a specific goal (Lovett, 2002). As shown in Figure 10.3, problem solving begins with recognizing a problem exists (you now weigh too much) followed by the development and use of strategies that solve it (you go on a diet) and the evaluation of the success of those strategies (you have either lost the holiday weight or not). Ill-defined problems require additional thought about what constitutes an acceptable solution and how the solution should be justified. Reconfiguring an ill-defined problem into a set of well-defined problems can be helpful. If your ill-defined problem is to improve your appearance, you could divide this into well-defined problems like returning to your preholiday weight, eating five servings of fruits and vegetables per day, and exercising at least 30 minutes each day. Effective problem solving can be achieved by following a system proposed by  Polya (1957). If you reach step 4 and the problem is solved, you can exit the system. If the problem is not solved, you return to step 1 and try again. Because good problem-solving skills are important to psychological well-being, we will examine the process in detail using four steps (Polya, 1957): Understand the problem. Make a plan. Carry out the plan. Look back. Given the close relationship between cognitive psychology and computer science that we described in Chapter 1, we should not be too surprised to see problem-solving as a type of looping computer program. If we reach step 4 and our solution has taken us to where we want to go, we stop. If we reach step 4 and our problem still exists, we return to earlier steps to try another solution or generate new solutions. This looping of steps, reminiscent of looping statements in computer programs, continues until the problem is resolved. Problems that are more complex than our weight-loss example might require a systems engineer. Systems engineering is a Gestalt type of process for problem solving that considers the whole problem to be distinct from the parts (Ramo, 2005). Systems engineers use a looping program that differs from our four-step process in that evaluation takes place each step of the way (see Figure 10.4). Unlike our simple four-step problem-solving model, systems engineering evaluates progress along every step of the way, not just at the end of one attempted solution. Although carefully formulating a problem takes time, this is generally time well spent. All relevant data should be collected, analyzed, and organized. What do we know? What information do we need that is missing? How does all this information fit together? An important part of this step is to represent or frame the problem in a useful way (Lovett, 2002). Earlier in this chapter, we talked about forming mental representations of experiences that subsequently can be manipulated by the mind. In the case of problem solving, the mental representations we form relate to how we see the problem. For example, you might represent your weight problem as the result of your holiday splurge or as the result of a broken bathroom scale. These two representations clearly lead to different solutions, and in many cases, your representation will determine how successful you will be at solving the problem. Psychologists have identified several helpful suggestions for making the most useful representations of problems and for avoiding some common mistakes that frequently lead to failure. For example, big, long-term problems are easier to solve if they are approached through components or intermediate goals. Your primary goal in college is to obtain a degree, but it is useful to consider how you plan to meet intermediate goals such as completing your general education courses, your major courses, and electives. Like ill-defined problems, big complex problems, such as world hunger, can be tackled best by breaking the problem into smaller, intermediate problems. Personal biases can interfere with good problem solving. In our weight example, a reluctance to reduce treats might lead you to conclude that the bathroom scale is at fault instead of your behavior. Your amount of self-efficacy or belief in your abilities to succeed might also influence your approach to a problem (Bandura, 2001). You might believe that dieting doesn’t work, so there is no point in even trying. By recognizing these biases, you can approach your problem and its potential solutions with a more open mind. Another barrier to forming useful representations of a problem is functional fixednessfunctional fixednessA possible barrier to successful problem solving in which a concept is considered only in its most typical form.            functional fixedness        A possible barrier to successful problem solving in which a concept is considered only in its most typical form.            , or a person’s tendency to think about a concept in its most typical form and no others. In an emergency, a belt or a computer cord can be used to tie a door shut, and a pot of hot coffee can be a weapon. In an emergency, people need to use whatever they have in hand to solve problems. Functional fixedness might lead you to believe that a belt can only hold up your pants, but it can also make it harder for someone to come through a door. A plan to solve your problem involves generating possible solutions and then choosing the best one to implement. Generating possible solutions involves creativity, but most importantly, it requires time. People who spend the most time on a problem typically generate the most diverse solutions. Generating the most solutions raises your chances of finding one that will work. Several factors can interfere with finding appropriate solutions. You might be so upset about the numbers on the bathroom scale that you refuse to consider efforts to lose weight. Some people dislike risk so intensely that they fail to consider a full range of alternative solutions. To escape the chaos and the ambiguity involved with facing a problem, people can rush to find a solution, overlooking more appropriate courses of action. Judging and discarding solutions too early in the process also leads to failure. Generating impractical solutions requiring resources we don’t have is not useful. An expensive stay at a weight reduction spa might work, but it probably doesn’t fit a student budget. Understanding that we have these weaknesses in our approach to problem solving should help us avoid them in the future. Some types of problems lend themselves to precise, step-by-step rules for reaching a particular solution, known as algorithmsalgorithmsA precise, step-by-step set of rules that will reliably generate a solution to a problem.            algorithms        A precise, step-by-step set of rules that will reliably generate a solution to a problem.            . Algorithms have the advantage of producing an accurate solution reliably. Let’s assume you have a three-number combination lock on your bicycle, but you have forgotten the combination. You can start with using 001 for the first input, then 002, and so on, until you reach the correct solution for unlocking your bike. Algorithms are efficient when run by a computer, but their cost when used by the human brain can be high. You could be very late to your next class by the time you unlock your bike. Because of the time needed to use algorithms, we often substitute rules of thumb, or shortcuts to problem solving, known as heuristicsheuristicsA shortcut to problem solving; also known as a rule of thumb.            heuristics        A shortcut to problem solving; also known as a rule of thumb.            . Because heuristics do not go through the exhaustive evaluation of solutions required by algorithms, they are faster. Another advantage of heuristics is that they typically require far less information than algorithms do. However, unlike algorithms, heuristics do not guarantee a solution. When aggressive children are asked how to solve social problems, such as persuading another child to share a desirable toy, they generate fewer solutions than do more prosocial children. Eventually, most children will generate an aggressive solution (grab the doll and run), but perceiving additional options (trading a piece of candy for the toy or arguing that sharing is nice) might make it less likely that the prosocial child will use the aggressive solution. Recipes are examples of algorithms. If you follow the recipe step by step, you should be able to produce the cookies you want every time. Not only can heuristics fail to find a solution, they can lead us in the wrong direction. Amos Tversky and Daniel Kahneman identified several heuristics that can produce faulty decisions (Tversky & Kahneman, 1973,  1974). The first type, the availability heuristicavailability heuristicA rule of thumb in which the frequency of an event’s occurrence is predicted by the ease with which the event is brought to mind            availability heuristic        A rule of thumb in which the frequency of an event’s occurrence is predicted by the ease with which the event is brought to mind            , is used when people predict that events that are easy to think about will be more frequent. For example, dramatic media reports make people think shark attacks are more common than they are. If we asked which is more common, being killed by a shark or being killed by falling airplane parts, which would you choose (see Figure 10.5)? You might be surprised to learn that you have 30 times the risk of being killed by falling airplane parts than by sharks (Plous, 1993). In the aftermath of 9/11, with its vivid imagery of airplanes crashing, more Americans chose to drive rather than fly. The extra traffic that resulted from fear of flying led to an estimated 9% increase in automobile fatalities, compared to typical rates, in the 3 months following the attacks (University of Michigan Transportation Research Institute, 2004). Which is more likely? Being hit by an airplane part or being attacked by a shark? The availability heuristic leads us to believe that events that are easy to think about are more frequent. Because of the frequent media coverage of shark attacks, such as Rodney Fox’s close call with a great white in Australia, people think shark attacks are common. You might be surprised to learn that you are 30 times more likely to be killed by falling airplane parts, like this turbine engine that fell from the sky onto a car in Brazil, than by a shark. As we mentioned earlier in this chapter, people often form prototypes or average examples when thinking about a category. These prototypes then represent the category when we are deciding which new examples might also fit the category. Tversky and Kahneman’s second type of heuristic, the representativeness heuristicrepresentativeness heuristicA rule of thumb in which stimuli similar to a prototype are believed to be more likely than stimuli that are dissimilar to a prototype.            representativeness heuristic        A rule of thumb in which stimuli similar to a prototype are believed to be more likely than stimuli that are dissimilar to a prototype.            , leads people to estimate that stimuli similar to a prototype are more likely to fit the category than are stimuli different from the prototype. To illustrate this heuristic, Tversky and Kahneman asked research participants whether Thomas, who is short, slim, and loves poetry, is more likely to be an Ivy League classics professor or a truck driver. Most people assumed that Thomas would be a classics professor because his description is closer to that of a prototypical professor than a prototypical truck driver. However, this conclusion is statistically quite unlikely. There are few Ivy League classics professors, and even if most fit Thomas’s description, the numbers would still be quite low. In contrast, there are thousands of truck drivers in the United States. Even if a small proportion of them shared Thomas’s characteristics, the numbers would be large. Consequently, the odds are that Thomas is a truck driver. Heuristics are most likely to fail when a correct solution requires a sophisticated understanding of probability (Fenton & Neil, 2012). For example, a classic American television show originating in the 1960s called Let’s Make a Deal usually ended with a contestant facing three doors (Behind door number one…) and knowing that a huge prize, such as a car, was behind one door, and worthless prizes were behind the other two. After the contestant selects a door, but before its contents are known, the host reveals that one of the unchosen doors has a worthless prize and asks whether the contestant wishes to switch. Most people erroneously stick with their first door in the mistaken belief that they now have a 50% chance of winning. In fact, their chance of winning with their chosen door remains one-third, but they have a two-thirds chance of winning if they switch. Here’s why. When the contestants first choose, their chance of winning is one-third. When the host reveals another door, he must reveal one of the losing doors no matter what the contestant chose first. If the contestants initially guessed correctly and stay with their original decision, their chance of winning remains one-third. However, if the contestants guessed incorrectly when first asked, switching now guarantees a win, making their chance of winning two-thirds if they switch. The trick here is that all the options seem equal (there is a one-third chance of winning, the host reveals one-third of the unknown, and the contestant can switch to the other one-third option), yet they are not truly so (Fenton & Neil, 2012). Although some of these examples make it sound like heuristics lead to bad decisions, the ability to use heuristics to make quick, effective, and efficient decisions was a significant adaptive advantage for our ancestors (Haselton et al., 2009). An example of an effective heuristic is the recognition heuristicrecognition heuristicA rule of thumb in which a higher value is placed on the more easily recognized alternative            recognition heuristic        A rule of thumb in which a higher value is placed on the more easily recognized alternative             (see Figure 10.6), which predicts that people will place a higher value on the more easily recognized alternative (Gigerenzer, 2008). In one study, American college students were asked which of two cities was larger. In making size decisions about German cities, such as Hamburg and Munich, students tended to choose the city they recognized most (Goldstein & Gigerenzer, 2002). They were correct about 73% of the time (Hamburg has about 1.8 million residents compared to Munich’s 1.3 million). The recognition heuristic has been shown to beat more conventional means of selecting stocks. Companies whose names were recognized by the most people also had stocks that performed better than the overall markets (Reips, 2006). The recognition heuristic predicts that if you think the film Finding Dory sounds more familiar than the film Keeping Up with the Joneses, you will correctly judge Finding Dory as generating more international revenue for the producers than Keeping Up with the Joneses. Once we have generated a set of solutions, we must decide which one to try first. How is this decision reached? The affect heuristicaffect heuristicA rule of thumb in which we choose between alternatives based on emotional or gut reactions to stimuli.            affect heuristic        A rule of thumb in which we choose between alternatives based on emotional or gut reactions to stimuli.             is particularly relevant to the way people make important choices (Slovic, Peters, Finucane, & MacGregor, 2005). According to this approach, we use our emotional responses to each choice to guide our decisions. Based on our past experience with similar choices, we develop a gut reaction to our options, pushing us toward alternatives we expect to produce desirable outcomes and away from alternatives we expect to produce undesirable outcomes. Our decision making is also affected by the need to avoid the emotion of regret (Connolly & Zeelenberg, 2002). By considering ways to justify the reasons for their decisions in advance, people can live more comfortably with the decisions they have made. An alternate approach to decision making, the utility theory, is also popular in economics. According to this theory, we compute the expected outcomes of our choices and select the best likely one. The expected outcome is computed by multiplying measures of the usefulness of the outcome by its expected probability. For example, to choose an elective course for your next term, you might consider a course that provides positive outcomes, such as being interesting and satisfying a graduation requirement. At the same time, you wish to avoid negative outcomes, such as getting a poor grade or spending a lot of money on materials. If you weight each outcome according to its probability and add up the results, you will end up with your own mini cost–benefit analysis. The representativeness heuristic makes us believe that stimuli similar to a prototype are more likely than stimuli that are dissimilar. Katrina Hodge, 2009 Miss England, may not fit your prototype of a Lance Corporal and Iraq War veteran. However, there are many more soldiers than beauty queens, so the likelihood that a beautiful woman is a soldier is higher than the likelihood that she is a beauty queen. You might find that applying utility theory is useful when faced with an important decision, such as whether to accept a job offer with modest pay in your hometown or one with higher pay in another state. It is clear, however, that we rarely make decisions by solving equations. Even when utility is held constant, people show a preference for one solution or the other based on how the solutions are framed. People rate basketball players who are described as making 75% of their free throws higher than those who are described as missing 25% of the time, even though the math is identical in both cases. Medical treatments that are described as effective 80% of the time are viewed more positively than those that fail 20% of the time. Even though we might carefully weigh the pros and cons of buying one laptop over another, the affect heuristic suggests that we use our emotional or gut responses to make decisions too. Tversky and Kahneman (Tversky & Kahneman, 1987) illustrated the importance of framing in decision making using an Asian disease problem. Even though the outcome in both situations is that 400 people will die, 72% of respondents preferred a more secure solution when the problem was framed using the word saved. In contrast, when the problem was framed using the word die, the secure solution was preferred by only 22% (see Figure 10.7). As we mentioned earlier, the way a problem is represented or framed can have a large effect on whether it will be solved. Framing can affect the choice of a solution through its interaction with a person’s willingness to select risky solutions. When a problem is framed in terms of losses, as in the will die framing of the Asian disease problem, people are more comfortable choosing the risky solution. In contrast, when a problem is framed in terms of gains, as in the saved frame of the Asian disease problem, people generally become more cautious. If we have already saved 200 people, we don’t want to risk saving fewer. Amos Tversky and Daniel Kahneman’s classic Asian disease problem asks people to choose one of two solutions to the following problem: If a disease was coming to the United States, and 600 people were expected to die, what should the president do? Both solutions resulted in the deaths of the same number of people (400), but one was phrased positively (200 will be saved) and the other was phrased negatively (400 will die). When the question was framed negatively, people were more likely to choose the riskier alternative. Good decision making is a skill that can be taught (Baron & Brown, 1991), and those who have received formal training in decision making make better real-world choices (Larrick, Nisbett, & Morgan, 1993). Psychologists have identified skills that predict decision-making competence, such as a good understanding of probability (Parker & Fischhoff, 2005). How well do these decision-making skills predict behavior in the real world? When participants’ performance on the identified skills was compared with real-life decision making, such as buying new clothes or shoes they never wore, strong correlations were observed between their abilities on the identified skills and the quality of their real-world decision making (Bruine de Bruin, Parker, & Fischhoff, 2007). Your belief that you can implement a particular solution will determine whether you decide to pursue that solution or look for another solution. Once you have decided on a solution, it is time to try it out. Measures of decision-making skills, such as a person’s understanding of probability, are negatively correlated with poor real-world decision making, such as the number of times you buy things you never use. At this point, one of the most critical elements in successfully implementing your solution is planning. Solutions that might otherwise succeed can fail when people do not anticipate the time and the resources needed for implementation. It is one thing to decide that you need to exercise more to lose your holiday weight, but without further planning, this solution might not work. How much exercise will you need? What activities should you do? When? Where? Is your solution practical? If you are a couch potato, thinking you will implement your exercise solution by training for next month’s marathon might not be realistic. If time management is not your strongest skill, you might consider tools like an online calendar or a bullet journal. Many techniques for helping you manage your time are available, including online calendaring and bullet journals, such as the one shown in this image. As you implement your solution, you need to know whether it is bringing you closer to your goal, which usually means that you need some measureme of success. In the example of holiday weight gain, the logical way to assess progress is to get back on the scale at regular intervals. At the same time, solutions usually require time to work, and a failure to make immediate progress should not be the basis for discarding a promising solution. Evaluation is an ongoing process, but it is especially important once a solution has been fully implemented. You might have predicted that 6 months of exercise should return you to your goal weight. At the 6-month point, we return to the original problem. Does it still exist? If not, the problem has been solved, and you can move on to other issues, although keeping up your exercise program is always a good idea. If the problem still exists, you return to the make-a-plan step and try again. Maybe this time you need to combine exercise with counting calories. People have a reasonably effective commonsense approach to making decisions, but again, careful psychological research can point out where we are vulnerable to poor decision making. If you find yourself unhappy with outcomes of some of your previous decisions, following the steps in this section on future occasions might help you find better solutions. You might recall hearing about the epic battle between world chess champion Garry Kasparov and IBM’s Deep Blue that ended in defeat for Kasparov in 1997. More recently, AlphaGo defeated several champion Go players (Silver et al., 2016). What makes this a remarkable achievement for AlphaGo’s programmers is the possibility of possible moves in the typical game of Go, dwarfing the already huge number of options in the typical game of chess. This remarkable achievement parallels the four problem-solving steps we reviewed in this section. The programmers began by helping their AlphaGo neural network to understand the problem by training it on 30 million board positions taken from real-life games on a Go database. The neural networkmade plans by estimating the likelihood that a particular move will lead to a win. In the next step, these plans werecarried out repeatedly. Most importantly, the program contained alook back strategy the programmers refer to as deep reinforcement learning while playing itself (see Figure 10.8). Now, instead of evaluating moves from the real-life games, AlphaGo generates its own moves and estimates the likelihood that each move will lead to a win, leading to an ongoing tsunami of improvement in the program’s capability. The AlphaGo program recently beat one of the world’s best human Go players, a feat considered nearly impossible with current technology due to the number of possible moves that characterize the game. The neural network program combined policies, or the selection of moves, with values, which predict whether a move will produce a win. Does this mean that our brains are destined to be outmatched by the machines? Not quite yet. Recall that even AlphaGo needed input from real-life games played by real-life people to get started. What processes can we observe in the brain during decision making? As we have seen on previous occasions in this textbook, observing the effects of brain damage on a behavior can illuminate the contributions of particular parts of the brain to that behavior. Damage to the frontal lobes of the brain, as in the case of the unfortunate Phineas Gage described in Chapter 4, reliably produces impulsivity and poor judgment. Patients with this type of damage often begin to gamble obsessively, turn their personal lives upside down, and become unemployable. Sometimes we need to make fast decisions, perhaps at the expense of accuracy. Different levels of activity in the subthalamic nucleus, part of the basal ganglia (see Chapter 4), are associated with fast and more cautious decision making (Herz et al., 2017). At other times, you might feel like you are of two minds when faced with a decision, and this is not so far from the truth. In reality, three major brain circuits interact during decision making (Goschke, 2014). One circuit assigns value to situations along the lines of pleasure or pain and involves the ventromedial prefrontal cortex, the orbitofrontal cortex, the nucleus accumbens, and the amygdala. A second circuit is an impulse control network that controls unwanted responses and includes the lateral prefrontal cortex and the parietal cortex. Finally, an attentional circuit monitors significant stimuli and involves the insula, the anterior cingulate cortex, and the amygdala. This circuit also seems to be involved with more complex social decision making, such as deciding whom to trust (Rilling & Sanfey, 2011). The value circuit, which is impulsive, gradually comes under the control of the impulse control circuit as we mature and are exposed to the social rules of our community (Bechara, 2005). As college students, you are a prime example of this maturity. Spending long hours studying and writing papers produces immediate pain but also promises the future pleasure of obtaining an interesting job and making enough money to support yourself and perhaps a family. Making simple decisions about what to keep and what to throw away can be difficult for some individuals. Hoarding behavior is correlated with unusually low levels of activity in the anterior cingulate cortex (Saxena et al., 2004). Drug addiction provides an interesting example of what happens when these normal decision-making circuits are disrupted. In many ways, drug addicts behave similarly to people who have brain damage in circuits related to decision making. Through their experience with drugs and possibly because of some biochemical consequences of addictive substances, the impulsive system gains control over the impulse control system. The immediate pleasure promised by the drug experience overwhelms the impact of negative future events such as lost jobs, disrupted family life, and even prison. Addicts begin to experience exaggerated responses to the potential reward of drug cues while becoming less responsive to other types of reward (Bechara, 2005). Hyperactivity in this impulsive reward system seems to progressively weaken impulse control. As you will see in Chapter 11, the prefrontal cortex is one of the last parts of the brain to mature (development continues into the early 20s), which might account for some of the impulsive, risky decisions made by adolescents (Blakemore & Robbins, 2012). At the same time that their impulse control system is relatively weak, adolescents might be hypersensitive to reward. Developmental changes in brain structure and function also account for the effects of peers on adolescent risk taking. Teens and young adults make about the same number of risky decisions while alone, but teens are more likely than young adults to make risky decisions in the presence of their peers. As shown in Figure 10.9, parts of the reward circuit were especially active in adolescents making a risky decision in the presence of peers.(a) The stoplight driving game is a simulation in which participants are told to reach the end of a track as quickly as possible. (b) Adolescents driving alone do not make more risky decisions than young adults or older adults, but they make many more risky decisions in the presence of a peer. (c) The ventral striatum, in orange, is part of the brain’s reward pathways. It is also crucial to addiction. (d) This graph shows the amount of change in the ventral striatum for the three age groups in the alone and peer-present conditions. Many variables influence an individual’s approach to decision making. The instrument in Table 10.2 was designed to identify which type of style you use (Scott & Bruce, 1995). Listed below are statements describing how individuals go about making important decisions. Please indicate whether you agree or disagree with each statement. Strongly DisagreeSomewhat DisagreeNeither Agree nor DisagreeSomewhat AgreeStrongly Agree1. I double-check my information sources to be sure I have the right facts before making a decision.123452. When making a decision, I rely upon my instincts.123453. I often need the assistance of other people when making important decisions.123454. I avoid making important decisions until the pressure is on.123455. I generally make snap decisions.123456. I make decisions in a logical and systematic way.123457. When I make decisions, I tend to rely on my intuition.123458. I rarely make important decisions without consulting other people.123459. I postpone decision making whenever possible.1234510. I often make decisions on the spur of the moment.1234511. My decision making requires careful thought.1234512. I generally make decisions that feel right to me.1234513. If I have the support of others, it is easier for me to make important decisions.1234514. I often procrastinate when it comes to making important decisions.1234515. I make quick decisions.1234516. When making a decision, I consider various options in terms of a specific goal.1234517. When I make a decision, it is more important for me to feel the decision is right than to have a rational reason for it.1234518. I use the advice of other people in making my important decisions.1234519. I generally make important decisions at the last minute.1234520. I often make impulsive decisions.1234521. I explore all my options before making a decision.1234522. When I make a decision, I trust my inner feelings and reactions.1234523. I like to have someone to steer me in the right direction when I am faced with important decisions.1234524. I put off making many decisions because thinking about them makes me uneasy.1234525. When making decisions, I do what seems natural at the moment.12345For each item, you will choose a score between 1 (strongly disagree) and 5 (strongly agree). When you’re done, add up your scores for the following groupings: Group R: 1, 6, 11, 16, 21Group I: 2, 7, 12, 17, 22Group D: 3, 8, 13, 18, 23Group A: 4, 9, 14, 19, 24Group S: 5, 10, 15, 20, 25The question groups are relevant to the decision styles in this order: Rational, intuitive, dependent, avoidant, and spontaneous. While you may have a dominant style, these scores are not mutually exclusive. People use multiple styles depending on the amount of information they have at hand and the timing of the decision. Rational decision-makers use reasoning and logic to arrive at solutions, while intuitive decision-makers rely on emotion and feelings. Dependent decision-makers rely on other people to point them in the right direction. Avoidant decision-makers postpone making any decision while hoping a situation will resolve without any actions on their part. Finally, spontaneous decision-makers focus on the immediate needs of a situation. Do your results fit with your experience? Are you generally satisfied with the decisions you make? In this chapter, we argue that decision-making ability is something you can learn to improve, so if you are not pleased with many of your past decisions, it is possible to change. Type of heuristicDefinitionExampleAvailabilityEvents that are easy to think about are more likely. Despite news and missing child reports that make kidnappings appear to be common, fewer than 100 children per year are abducted by strangers in the United States. RepresentativenessStimuli that are similar to a prototype are more likely than stimuli that are different from the prototype. A big, muscular student at Ohio State University is probably a football player (even though fewer than 100 of Ohio State’s 60,000-plus students are on the football team). RecognitionA more recognizable stimulus has a higher value. Wine labeled as California wine is rated higher than the same wine labeled North Dakota wine. AffectWe use an emotional response (gut feeling) to choose one alternative over another. Eating dessert instead of staying on your diet is an emotional choice. LanguageLanguageA system for communicating thoughts and feelings using arbitrary signals.            Language        A system for communicating thoughts and feelings using arbitrary signals.             is a system for communicating thoughts and feelings using arbitrary signals, such as voice sounds, gestures, or written symbols. As we discussed previously, language provides us with powerful tools for organizing and manipulating our thinking, problem solving, and decision making. Although thoughts can be represented visually as well as verbally, language extends our thinking abilities to abstract concepts such as truth and beauty that would be difficult to visualize. Above all, language connects us with others. Not only can we communicate with people in our immediate vicinity, but language spans time and distance, allowing us to share the thoughts of people living long ago and in distant places. Because of language, the thoughts we record today might reach into the future to influence the thinking of people not yet born. Language both reflects and shapes thought. Benjamin Lee Whorf’s hypothesis of linguistic relativity examines the effect of having a rich vocabulary on a person’s ability to think about a topic (Whorf, 1956). According to Whorf, a skier who can name and identify powder, slush, and other variations of snow thinks differently about snow than does a person born and raised in a tropical climate. Whorf’s theory correctly predicted that the use of gender-free words such as server instead of waiter or waitress or flight attendant instead of stewardess would reduce gender stereotyping and discrimination (Sczesny, Formanowicz, & Moser, 2016). Further efforts to address the binary nature of English personal pronouns (he or she) to better reflect a continuum of gender identity have led to the use of completely gender-neutral pronouns (Miltersen, 2016). According to Benjamin Lee Whorf, a skier who knows what early sintering means, is able to think differently about snow than a person who is unfamiliar with the term. Sintering occurs when snow crystals break down and fuse into larger crystals. To fix the emergence of human languages in time, we can assume that certain complex social behaviors would be difficult to conduct without the ability to speak. Elaborate tool use and cooperation would be easier to accomplish using language. Because our version of the human species, Homo sapiens, appeared between 100,000 and 200,000 years ago, most anthropologists are convinced that human language existed at that time, if not earlier. A critical gene mutation in the FOXP-2 gene occurring around 100,000 years ago possibly marked the start of modern language (Corballis, 2004). Regardless of timing, the enormous advantages of language to human culture and cooperation would ensure its continuity. Much evidence points to Africa as the source of the first human languages. Some anthropologists suggest that it would be difficult for early humans to migrate successfully to other continents without the cooperation provided by language. Taking a different approach, an analysis of more than 500 contemporary languages has demonstrated that the number of speech sounds in a language decreases systematically with the culture’s distance from Africa along migration routes (Atkinson, 2011). Many African languages feature more than 100 speech sounds, compared to 45 in English and 13 in Hawaiian (see Figure 10.10). The number of phonemes or speech sounds per language decreases with the distance of the culture using the language (indicated by shades of red) along migration routes from the western coast of Africa. Many African languages feature more than 100 speech sounds, compared to 45 in English and 13 in Hawaiian. Language is intimately connected to cultural values. For example, the English language contains many words that signify the passage of time. In contrast, the Hopi Native American tribes have only two words relevant to time, loosely translated as sooner and later (Le Lionnais, 1960). What does this difference tell you about the two cultures? Languages are living entities, under constant pressure to change. Nearly half the world’s spoken languages may soon be lost. Following assimilation into larger cultures, speakers stop using their native languages or fail to transmit them to their children (Malone, 2006). With each language lost goes an opportunity for scientists to understand the unique local knowledge of a culture, along with the historical and cognitive implications of the language. Language works like a set of building blocks, beginning with basic speech sounds (phonemes), which are combined into meaningful units (morphemes) and then combined in meaningful strings according to the rules of grammar. Humans produce more than 500 phonemesphonemesA speech sound.            phonemes        A speech sound.             or speech sounds, such as the c in cat. The number and types of phonemes are limited only by the physical features of the human vocal apparatus. Not all phonemes appear in all languages. Individual world languages vary from as few as 11 phonemes to more than 140 (Holt, Lotto, & Kluender, 1998). English features about 45 phonemes, which we represent visually using the 26 letters of the alphabet either singly (s) or in combination (sh). Most written languages attempt to match visual symbols to phonemes, although many new readers of English struggle with the different pronunciations represented by the same letters, as in the ough in through, rough, trough, slough, or thought. Phonemes are combined into morphemesmorphemesThe smallest component of speech that carries meaning.            morphemes        The smallest component of speech that carries meaning.            , which are the smallest components of speech that carry meaning. Most morphemes are words, but word prefixes (as in preschool and suburban) and word endings (as in dogs and walked) also qualify as morphemes because they change the meaning of the root word. English contains approximately 100,000 morphemes, which can be used to produce more than a million words. The average 20-year-old native English speaker knows about 42,000 words, in addition to thousands of proper nouns (names) and other versions of the main words (Brysbaert, Stevens, Mandera, & Keuleers, 2016). Education and age increase this number to a high of nearly 60,000 words (see Figure 10.11). Click languages include sounds made by clicking the tongue and might be among the earliest forms of language used by humans. Two trends characterize the growth of vocabulary: age and education. A gradual increase in vocabulary takes place over the adult lifespan. People’s level of education is also predictive of the number of words they know. Morphemes are combined into phrases and sentences according to rules of grammar. For example, different languages have their own rules about the meaningful ordering of nouns and adjectives. In English, you say the brown dog but not the dog brown, while the reverse is true in Spanish. This type of natural grammar is usually learned early in childhood by interacting with other speakers, in contrast to the formal grammar instruction featured in schools. As we discussed in Chapter 4, language is typically managed by the left hemisphere of the brain. Further insights into the localization of language processing result from investigations of brain damage and efforts to teach language to nonhuman animals. We can learn about the biology of language by surveying problems that arise because of brain damage resulting from head injury or stroke. AphasiaAphasiaThe loss of the ability to speak or understand language            Aphasia        The loss of the ability to speak or understand language             is the loss of the ability to speak or understand language. The closely related processes of reading and writing are often, but not always affected by aphasia. In 1861, Paul Broca conducted a case study of a 51-year-old man named Louis Leborgne, who had been institutionalized for more than 20 years (Domanski, 2013). Leborgne came to be called Tan, because when questioned, tan was one of a few syllables he could produce. Leborgne entered the hospital after several months of being unable to speak. He apparently understood much of what was said to him and retained his ability to answer numerical questions by raising an appropriate number of fingers on his left hand (Herrnstein & Boring, 1965). After Leborgne died, Broca performed an autopsy on his patient’s brain and found significant damage to the patient’s left frontal lobe, possibly because of Leborgne’s long history of epilepsy. The damaged area is now called Broca’s area in honor of Broca’s discovery (see Figure 10.12). Today, Leborgne would be diagnosed with Broca’s aphasia. This condition is characterized by difficulty producing speech. The speech that the patient manages to produce is slow and effortful, but it generally makes sense. In some cases, patients retain the ability to curse, as in one of Broca’s other patient’s Sacre nom de Dieu! (In the name of God!), which he uttered in frustration when unable to make himself understood with gestures. A contemporary patient with Broca’s aphasia described his condition by saying, Speech … can’t say … talk, you see (Gardner, 1976, p. 61). About 13 years after Broca presented his revolutionary work on Leborgne, Carl Wernicke published his observations on another type of language deficit (Wernicke, 1874). In honor of his contributions, this syndrome is now called Wernicke’s aphasia, and the affected area of the brain is known as Wernicke’s area. Wernicke’s area is located near the primary auditory cortex, located in the temporal lobe. The symptoms of Wernicke’s aphasia could hardly be more different from those of Broca’s aphasia. Where Broca’s aphasia affects the production of speech, Wernicke’s aphasia affects its comprehension. In Broca’s aphasia, speech is slow and laborious but generally meaningful. In Wernicke’s aphasia, the opposite is true. Speech is rapid and fluent but virtually meaningless. A contemporary patient with Wernicke’s aphasia said,Oh sure, go ahead, any old think you want. If I could I would. Oh, I’m taking the word the wrong way to say, all of the barbers here whenever they stop you it’s going around and around, if you known what I mean, that is typing and tying for repucer, repuceration, well we were trying the best that we could while another time it was with the beds over the same thing. (Gardner, 1976, p. 68)If you don’t pay attention to the meaning, the speech of patients with Wernicke’s aphasia sounds normal, if slightly fast. Grammar is generally correct. On further examination, we find that meaningfulness is lacking. These patients are locked into a world without social connection, yet they do not seem aware of their circumstances or in apparent distress. It is simplistic to assume that the brain has only two main language centers, Broca’s and Wernicke’s areas. Instead, contemporary research has identified complex pathways for processing language that connect Broca’s and Wernicke’s areas to other cortical areas involved in cognition (Dronkers, Pinker, & Damasio, 2000;  Friederici, 2011). Later in this chapter, we discuss several approaches to learning language. The evolutionary approach suggests that language results from some innate capacity shaped by natural selection. Animals and human infants demonstrate similar perceptual grouping, or the linking together of sounds with certain characteristics like the tick-tock of a clock (Toro, 2016). This evolutionary view implies that we should find precursors of human language in the behavior of other animals. Many animals communicate with each other, often in complex ways. All forms of communication, however, do not involve the flexibility and the creativity of language. We can identify three major patterns of animal communication (Dronkers et al., 2000). One is an inflexible group of calls for signaling danger and identifying territories. A second contains signals that communicate magnitude, as in the case of bee dances. Finally, animals communicate through sequences of behavior, as in the case of birdsong. We don’t know to what extent these animal forms of communication may have served as precursors for human language. The most logical place to look for precursors to human language is the great apes. Chimpanzees, bonobos, and gorillas have a part of the brain analogous to the human Broca’s area. In both humans and apes, this area shows a difference in size between the right and the left hemispheres that might be correlated with language ability (Cantalupo & Hopkins, 2001). Many researchers have attempted to teach human languages to apes. In 1931, Winthrop N. Kellogg and his wife adopted a baby chimpanzee, Gua. Because of the limitations of the chimpanzee vocal apparatus, efforts to teach Gua to talk were doomed to failure (Kellogg & Kellogg, 1933). Allen and Beatrice  Gardner (1969) taught sign language to a chimp named Washoe. After 4 years of work, Washoe had mastered 132 signs. The Gardners’ efforts were followed by Francine  Patterson (1978), who trained a gorilla named Koko to use signs. Sue Savage-Rumbaugh and her colleagues (1998) have successfully taught a bonobo chimpanzee named Kanzi to associate geometric symbols with words. Even before his training began, Kanzi learned 10 symbols simply by observing his mother’s training sessions, although his mother never quite mastered the task. Kanzi also seems to be able to understand some human speech. When given 660 verbal requests, such as Put the collar in the water, Kanzi behaved correctly 72% of the time. In addition to investigations of language behavior in apes and monkeys, Irene  Pepperberg (2014) makes a strong case for her African grey parrots. While we use the phrase to parrot to indicate mindless mimicry, Pepperberg argues that her parrots demonstrate complex cognitions related to language. Others have proposed that dolphins, whales, dogs, and prairie dogs possess language capabilities (Bloom, 2004;  Caldwell, 1976; Janik, 2006;  Lilly, 1967;  Slobodchikoff, Perla, & Verdoli, 2009). The soundtracks of horror films, adventure films, dramas, and war films use sound features that characterize animal distress calls to heighten viewer arousal. It is likely that these sounds add to the fear produced by the visual images (Blumstein, Davitian, & Kaye, 2010). Whether animals demonstrate real language abilities is the subject of ongoing debate. Although children build vocabularies spontaneously, critics point out that ape language must be taught laboriously (Terrace, 1979). Word order does not seem to matter to apes, although it has an essential role in human language. Trainers of the apes might be making biased observations. When Washoe signed waterbird while observing a swan, the Gardners concluded that she was making a new, creative observation, but Washoe may simply have noticed a bird sitting on the water. Human infants use cognitive strategies for language learning that are not found in other animals (Toro, 2016). For example, infants pay more attention to consonants than to vowels by the end of their first year. Consonants are often more important sources of information for identifying words than vowels, as you probably already know from the ease with which you interpret txt mssgs. Whether we believe that animals have true language or not, we retain an enormous respect for both the complexity and the intelligence of animal behavior and the remarkable sophistication of human language. Learning language occurs differently than many types of learning. No specific instruction is needed, as it is for the related skills of reading and writing. A typical child exposed to language will learn language. Language learning begins very early. Korean children adopted by Dutch parents showed evidence of having retained information about the Korean language from prenatal exposure (Choi, Cutler, & Broersma, 2017). Early in life, between 6 and 12 months of age, children make an important perceptual shift that impacts their subsequent language learning. They become less successful in perceiving the differences between sounds that are not characteristic of their native language while becoming more successful at perceiving differences between sounds that do occur regularly in their native language (Kuhl, 2011). Underlying this transition is a type of computational or statistical learning, in which the infant pays attention to the frequencies of each type of sound they hear (see Figure 10.13). Efforts to teach sign language to chimpanzees have been more successful than efforts to teach them to speak. Here, the human instructor is teaching the chimpanzee to sign eye. In the second half of their first year, infants use social interaction as a gate for conducting computational evaluations of how often they hear certain speech sounds. As a result, they become less sensitive to sounds that are not in their native languages and more sensitive to those that are. These graphs show an idealized distribution of the frequencies of the /r/ and /l/ sounds in English and the Japanese /r/. Not just any type of exposure to language will engage the infant’s computational learning. Social interaction is an essential component of this process, and two-way interaction in the form of conversation produces maximum results. Because language evolved to allow communication with others, social interaction may serve as a gate for initiating the infant’s computational learning system (Kuhl, 2011). Conversing with children produces greater language competence than reading to them (Zimmerman et al., 2009). Even when exposure is one-way, such as when a child is listening to a speaker, more language learning occurs when a real person is speaking with the child face to face than when a child is listening to the same speaker on television (Kuhl, 2007;  Kuhl & Meltzoff, 1982). This finding implies that passive television or computer videos are unlikely to improve a child’s language learning. Irene Pepperberg’s African grey parrots have demonstrated sophisticated languagelike behaviors. For example, when shown an object, Alex could correctly state its color, shape, and material. After only six repetitions, he correctly referred to himself as gray when asked his color. Observations of the speed and ease with which very young infants can learn complicated language tasks have led to the assumption by many, including linguists Noam Chomsky (Chomsky, 1957) and Steven Pinker (Pinker, 1994), that humans have an inborn capacity for learning language. No human culture on Earth exists without language. Language acquisition follows a common course regardless of the native language being learned. Whether a child is exposed to English or Cantonese, similar language structures appear around the same point in development. For example, children all over the world go through a stage in which they overapply language rules, as in the case of a child saying goed instead of went. Eventually, the child switches to the correct forms, long before formal instruction. In addition, human brain structure is correlated with language. As we discussed in Chapter 4, most people process language in the left hemisphere of the brain. Damage to these left hemisphere language areas because of a stroke or other brain injury produces specific types of language deficits. Two-way interaction in the form of conversation produces the fastest language learning, reinforcing the social nature of this behavior. It is not necessary to assume, however, that we have a unique language module in the brain to account for the development of human language. Many linguists believe that spoken language was built on existing structures that allow primates to produce gestures (Corballis, 2009). Simultaneous vocalizations and gestures (pointing and saying look) could have been followed by a greater reliance on vocalizations, which is the same progression we see in children. Vocalization requires less energy than gesturing, as any sign language interpreter can tell you. It also allows communication to occur at night or when hidden, and it frees the hands for tool use and hand-to-hand combat. Assuming an inborn capacity for learning language further implies that language has a genetic basis. Several genetic conditions selectively affect individuals’ language-learning abilities. A family known as the KE family has members who have severe difficulties with the production of language accompanied by a mutation in the FOXP2 gene (Lai, Fisher, Hurst, Vargha-Khadem, & Monaco, 2001). This is the same gene suspected of mutating about 100,000 years ago, making modern human language possible. The FOXP-2 gene appears to be critical for learning to produce vocalizations (White, 2013). Socioeconomic differences impact language acquisition. By the age of 2 years, English-learning children from low-socioeconomic status Caucasian families were already 6 months behind children from wealthier homes in both vocabulary and language understanding (Fernald & Weisleder, 2015). Hart and  Risley (1995) proposed a language gap, characterized by the exposure to as many as 30 million more words to children in wealthier families than in poor families by the age of 3 years. This report, widely cited in the popular press, was consistent with a cultural deficit model, in which the poor performance of children from disadvantaged families resulted from low levels of cognitive stimulation. The cultural deficit model has been widely criticized as blaming parents for their children’s poor school performance and being insensitive to cultural differences in the ways parents interact with children. Quantity and quality of speech directed at young children are highly correlated, and Hart and Risley noted that quantity of words was just one indicator of possible quality of language exposure. However, the importance of the quantity of exposure remains hotly debated (Baugh, 2017). Many researchers argue that specific aspects related to the quality of the language input to the child, more so than its quantity, predicts later language skills (Ramírez-Esparza, García-Sierra, & Kuhl, 2014). For example, using parentese, or language deliberately simplified for use in communicating with children, was associated with better child language outcomes. The use of rich vocabulary, complex ideas, and back-and-forth conversation promotes language growth in children (Fernald & Weisleder, 2015). Efforts to build parents’ skills in nourishing their children’s language development can bring benefits to all, regardless of socioeconomic status. In most cases, individuals with intellectual disability experience difficulties with language, but individuals with Williams syndrome are fluent speakers with large vocabularies. Williams syndrome and another genetic disorder, Down syndrome, produce a similar level of intellectual disability, but language use in these two groups is quite different (Bellugi, Wang, & Jernigan, 1994). When asked to name all the animals he knew, a child with Down syndrome replied, Horsie, dog, ice cream. A child with Williams syndrome of the same age and with the same IQ score answered, Weasel, newt, salamander, ibex, yak. At the same time, it is not unusual for a person of normal to high intelligence to have significant difficulties learning language (Tallal, Ross, & Curtiss, 1989). Accomplished people who have been diagnosed with verbal learning disabilities or are suspected of having learning disabilities include such notables as Einstein, Sir Winston Churchill, Leonardo da Vinci, Thomas Edison, and psychology’s own William James. Language learning and use can vary widely, and these variations provide us with a richer understanding of how humans can communicate. We examine three variations of particular interest here. Why do some children have such a hard time learning to read? What happens when people learn more than one language? How does American Sign Language (ASL), which uses movement instead of sound, compare with more conventional spoken languages? Individuals with dyslexia experience difficulties in learning to read despite typical intelligence and exposure to adequate teaching methods (Shaywitz, Morris, & Shaywitz, 2008). The first description of a dyslexic patient, Percy F., was published by W. Pringle Morgan in 1896 (Shaywitz, 1996). Percy F. was described by Morgan as quick at games, and in no way inferior to others of his age. His great difficulty has been—and is now—his inability to learn to read (Shaywitz, 1996, p. 98). Carol Greider, a Nobel Prize–winning professor of molecular biology and genetics, struggled with dyslexia from elementary school through graduate school. Although the condition was challenging, Greider states, Perhaps my ability to pull more information out of context and to put together different ideas may have been affected by what I learned to do from dyslexia. Dyslexia is strongly influenced by genetic factors, which in turn result in differences in the symmetry of the cerebral hemispheres (Vanderauwera et al., 2016) and, in particular, the organization of fiber pathways in each hemisphere (Zhao, de Schotten, Altarelli, Dubois, & Ramus, 2016). People with dyslexia are more likely to be left-handed or ambidextrous than people without dyslexia (Eglinton & Annett, 1994). In addition to these differences in brain structure, people with dyslexia have difficulty distinguishing between similar-sounding phonemes or basic speech sounds, such as m or n (Merzenich et al., 1996). Compared to typical readers, their brains show different patterns of activation during rhyming tasks, which are based on the sound of words (Frith & Frith, 1996). Activity in the right prefrontal cortex during a rhyming task, which requires the ability to discriminate among phonemes, accurately predicted gains in reading skills over the next few years by children with dyslexia. Because reading most languages depends on matching phonemes to the letters that represent them, people with dyslexia show evidence of using a workaround when they read. Brain activity has been recorded while university students with and without dyslexia were reading (Shaywitz et al., 1998). Compared to typical readers, readers with dyslexia showed less activity in a pathway connecting visual cortex in the occipital lobe to Wernicke’s area in the temporal lobe. Instead, the readers with dyslexia showed greater activation of Broca’s area, which participates in speech production. Relying on Broca’s area while reading, as people with dyslexia do, is like reading out loud to yourself, which slows reading speed. If you have ever read a bedtime story to a child, you are aware of how much slower reading out loud is compared to reading silently. More than half the world’s population is bilingualbilingualProficient in two languages.            bilingual        Proficient in two languages.             or proficient in at least two languages (Chertkow et al., 2010; Kavé, Eyal, Shorek, & Cohen-Mansfield, 2008; see Figure 10.14). The 19th-century Italian cardinal Giuseppe Caspar Mezzofanti allegedly spoke 50 languages (Della Rosa et al., 2013). Bilingualism is associated with several benefits. Children with several types of bilingualism (Chinese–English, French–English, and Spanish–English) outperformed monolingual English speakers on tests of executive control (Antoniou, Grohmann, Kambanaros, & Katsos, 2016). Some researchers have reported that older adults who were bilingual experienced a delayed onset of symptoms of Alzheimer’s disease compared to monolingual older adults (Bialystok, Craik, & Luk, 2012). Being bilingual possibly contributes to cognitive reserve or protection against cognitive decline. However, a country-by-country analysis of multilingualism and cognitive decline yielded mixed results, and more research is needed on this topic (Klein, Christie, & Parkvall, 2016). Eleven languages are recognized in South Africa, and each province recognizes at least two languages. The most commonly spoken language in homes (23.8%) is Zulu. Many South Africans speak two or more languages. Brain areas involved with multiple languages appear to overlap (Pearce, 2005). The amount of overlap depends on the timing of learning and proficiency in each language. When a person learns two languages early in childhood, the extent of overlap in the brain is greater than when the second language is learned in adulthood (Kim, Relkin, Lee, & Hirsch, 1998). When a person is nearly equally skilled in two languages, more overlap will occur as well (Perani et al., 1998). ASL, used by people with hearing impairments and people who wish to communicate with them, provides further insight into the processing of language. ASL constitutes a distinct language, although it uses spatial cues of sight and movement instead of sound (Klima & Bellugi, 1979). ASL provides an interesting contrast between language functions, generally found in the left hemisphere of the brain, and spatial functions, generally managed by the right hemisphere. American Sign Language (ASL) is a distinct language based on sight and movement rather than sound. Both clinical observation and imaging studies support the notion that the brain manages ASL in the same way it manages other languages despite its obvious spatial characteristics. Prior to brain surgery, surgeons identify which functions are processed by each hemisphere in an individual patient’s brain by anesthetizing one hemisphere at a time. When the left hemisphere of an English-speaking patient proficient in ASL was anesthetized, she made errors in both spoken English and ASL signing. Neither anesthetizing the right hemisphere nor performing subsequent surgery on her right hemisphere produced deficits in either language (Damasio, Bellugi, Damasio, Poizner, & Gilder, 1986). Despite the spatial nature of ASL, this case suggests that a language is still a language, and the left hemisphere is the likely place for that language to be processed. These clinical observations have been confirmed by imaging studies. The same areas of the brain are activated during language tasks regardless of whether the subject uses spoken English or ASL (Neville et al., 1998). Type of aphasiaLocation of damageSymptomsBroca’s aphasiaBroca’s area (left frontal lobe in most people). Slow, effortful speaking combined with good comprehension. Wernicke’s aphasiaWernicke’s area (left temporal lobe in most people). Fluent, meaningless speech without comprehension. IntelligenceIntelligenceThe ability to understand complex ideas, adapt effectively to the environment, learn from experience, engage in reasoning, and overcome obstacles.            Intelligence        The ability to understand complex ideas, adapt effectively to the environment, learn from experience, engage in reasoning, and overcome obstacles.             is an individual’s ability to understand complex ideas, to adapt effectively to the environment, to learn from experience, to engage in various forms of reasoning, and to overcome obstacles (Neisser et al., 1996, p. 77). Along with Théodore Simon, Alfred Binet devised a test aimed at identifying schoolchildren with intellectual disability. Binet and Simon’s test laid the groundwork for today’s intelligence testing. The assessment, or testing, of intelligence represents an attempt to assign a number to an individual’s abilities, allowing that person to be compared with others. Formal intelligence testing began in 1904, when Alfred Binet was instructed by the French government to devise an objective assessment of schoolchildren. Binet and his colleague, Théodore Simon, assumed that relatively bright children behaved cognitively like older children, while less intelligent children behaved like younger children. They devised items that they believed would indicate children’s mental age relative to their peers. In this system, children who successfully completed an item at an earlier age than most of their peers would have a higher mental age, while those who were not able to complete an item until they were older would have a lower mental age. Stanford University professor Lewis Terman adapted Binet’s test for use in the United States and named his revised version the Stanford–Binet Intelligence Scales (Terman, 1916). Terman began using the intelligence quotient (IQ)intelligence quotient (IQ)A measure of individual intelligence relative to a statistically normal curve.            intelligence quotient (IQ)        A measure of individual intelligence relative to a statistically normal curve.            , which is computed by dividing children’s mental age by their chronological age and, for convenience, multiplying by 100. For example, a bright child with a mental age of 15 and a chronological age of 12 would have an IQ score of. The most frequently used intelligence tests today include the Stanford–Binet Intelligence Scales and the Wechsler Adult Intelligence Scale (WAIS). These tests no longer use the concept of mental age. Instead, contemporary tests place individual performance on a statistically normal curve, described in Chapter 2. Contemporary tests also incorporate new features designed to more accurately assess people of extremely low or high intellect, the elderly, and individuals with language difficulties. As we discuss in Chapters 2 and 12, constructing a good test can be challenging. A good test must demonstrate both reliability and validity. In short, the test should provide consistent results that correlate with other measures of the same construct. Although no test is perfect, most IQ tests show relatively good reliability and validity (Kaplan & Saccuzzo, 2001). It is important to keep in mind, however, that the intent of IQ tests is to predict school performance as opposed to the complex construct of intelligence described at the beginning of this section. Consequently, it is not surprising to find that correlations between IQ score and performance in mathematics and verbal skills, which are essential for success in contemporary education, are relatively high but correlations between IQ score and performance in art and design are lower (Deary, Strand, Smith, & Fernandes, 2007). Performance on the verbal components of many commonly used IQ tests are influenced by socioeconomic status, which further complicates the interpretations of the scores (Chapman, Fiscella, Duberstein, Kawachi, & Muennig, 2014). Improvements in scores over the last 60 years on tests that are supposedly culture free suggest that it may be impossible to separate test performance from environmental factors (Fox & Mitchum, 2013;  Nisbett et al., 2012; see Figure 10.15). Matrix reasoning tests are believed to be examples of culture-free and nonverbal intelligence tests. This category of testing is showing the largest increases in performance worldwide, suggesting that our modern experience is making us better at extracting abstract concepts. Which of the items labeled 1 through 8 fits in the lower right corner of the matrix? The correct answer to this item is 4. In discussions of intelligence, some psychologists focus on an individual’s overall abilities, while others focus on particular types of abilities. Using the statistical technique of factor analysis, which he helped develop, Charles Spearman distinguished between a general intelligence (g)general intelligence (g)A measure of an individual’s overall intelligence as opposed to specific abilities.            general intelligence (g)        A measure of an individual’s overall intelligence as opposed to specific abilities.             factor and specific factors that apply to single tasks (Spearman, 1904). For example, Spearman argued that g was important for learning Latin but not for distinguishing between two musical tones. General intelligence can be divided into fluid intelligence and crystallized intelligence (Cattell, 1971). Fluid intelligenceFluid intelligenceThe ability to think logically without the need to use learned knowledge            Fluid intelligence        The ability to think logically without the need to use learned knowledge             refers to the ability to think logically without needing previously learned knowledge, such as seeing patterns in a visual stimulus, while crystallized intelligencecrystallized intelligenceThe ability to think logically using specific learned knowledge            crystallized intelligence        The ability to think logically using specific learned knowledge             requires specific, learned knowledge, such as vocabulary or the multiplication tables. A person needs pattern recognition, a type of fluid intelligence, to play chess or Sudoku well, but understanding the rules of the game requires crystallized intelligence. Fluid intelligence peaks in young adulthood and then declines, although it declines more slowly in individuals who continue to use fluid intelligence regularly, while crystallized intelligence remains more stable through adulthood (see Figure 10.16). Fluid intelligence, like a reaction time measured with a stopwatch, includes abilities that do not require acquired knowledge. Fluid intelligence peaks in young adulthood and then gradually declines over the remaining life span. In contrast, crystallized intelligence, which does require acquired knowledge, remains fairly stable throughout adulthood. Composer John Williams has used his crystallized intelligence of music theory to contribute memorable soundtracks (for films including Jaws, Star Wars, and the Harry Potter series) in a career spanning more than six decades. General intelligence theories do not provide explanations for splinter skills or islands of ability that occur against an overall background of lower functioning. Gloria Lenhoff, who has Williams syndrome and an IQ of about 55, cannot make change for a dollar or subtract 3 from 5, but she has performed as a lyric soprano with the San Diego Master Chorale and as an accordionist with Aerosmith (Maher, 2001). Leslie Lemke, who is both intellectually disabled and blind, listened one time to Pyotr Ilyich Tchaikovsky’s Piano Concerto No. 1. Hours later, Lemke sat down at the piano, which he had never studied, and played the entire composition without error (Treffert & Wallace, 2002). Professional musicians are unlikely to be able to duplicate this feat. The separability of intelligences in these exceptional cases suggests that intelligence is a combination of factors rather than a single thing, such as the processing speed of your computer. Howard Gardner (1983, 1999) interprets these and similar findings to mean that we have multiple, independent types of intelligence. Robert Sternberg proposed a triarchic theory of intelligence, in which a combination of analytical, creative, and practical abilities allows people to achieve success (Sternberg, 1985;  Sternberg & Salter, 1982). He argues that it is possible to be gifted in one aspect without being gifted in others. Both general and specific approaches to intelligence can be useful. We can assume that people have separate strengths and abilities, such as those outlined by Gardner and Sternberg. Among these diverse abilities, purely cognitive abilities, such as verbal, mathematical, spatial, and logical skills, show strong positive correlations with one another, supporting an argument for general intelligence, or g. At the same time, abilities involving sensory, motor, and personality factors are less likely to show strong correlations, supporting an argument for multiple intelligences in these domains (Visser, Ashton, & Vernon, 2006). Traditional views of intelligence focused on education-related skills, but emotional and social skills are important to successful adaptation too. Building on arguments in favor of multiple intelligences, and in recognition that previous work on intelligence seemed to neglect social skills, models of emotional and social intelligence were proposed (Goleman, 2006;  Mayer & Salovey, 1993). Social and emotional intelligence allow people to manage emotions and reason about the mental states of others. Clinical cases involving individuals with brain damage, psychological disorders, and intellectual disability provide evidence for social and emotional abilities that are separate from cognitive abilities. In Chapter 7, we discussed roles for the prefrontal cortex, amygdala, and insula in emotion. Patients with damage to connections between these structures performed very poorly on a standard measure of emotional and social intelligence, even though they have a normal IQ score and show no evidence of other psychological disorders (Bar-On, Tranel, Denburg, & Bechara, 2003). Individuals with autism spectrum disorder often display cognitive abilities that are superior to their social abilities. Individuals with Down syndrome, which produces moderate intellectual disability, display relatively strong social skills (Fidler, Most, Booth-LaForce, & Kelly, 2008). Individuals with Williams syndrome provide examples of how general intellect can diverge from other abilities and talents. Gloria Lenhoff (right), has a tested IQ score of 55 but has performed as a lyric soprano and has played the accordion with Aerosmith. Even if emotional and social intelligence can be separated from traditional measures of intelligence, these factors can still exert a strong influence on a person’s academic and professional outcomes. In global assessments of math and science proficiency, students from East Asian countries (China, South Korea, and Japan) consistently outscore students from the United States and the European Union, who score around the mean (Guglielmi & Brekke, 2017). Further analysis suggests that the advantage shown by East Asian students is largely predicted by environmental factors, including parents’ educational goals for their children, students’ own educational goals, work ethic, and self-perception. Student self-perception includes a sense of academic efficacy (I can do this) and self-concept (I’m good at this). A not very intuitive finding is that self-concept related to math and science achievement is lowest in the very nations where performance is best! Overestimating one’s abilities and achievement can result in poorer performance. As described in more detail in the Hub Science feature in this chapter, a student’s mindset regarding improvement can also influence performance. The East Asian cultural norms of viewing the self as worthy of improvement increases students’ willingness to accept negative feedback and make corrections (Guglielmi & Brekke, 2017). Some psychologists view social and emotional intelligence as different from school-based intelligence and equally if not more important for success. In a classic study, children were given a single marshmallow with instructions to not eat it when an experimenter left the room. They were told that if they did not eat it, they would receive two marshmallows when the experimenter returned. When the children were tracked down 12 years later, the two-thirds who had been able to delay gratification (they didn’t eat the marshmallow) were less stressed and more confident than the one-third who had not been able to delay gratification (Mischel, Ebbesen, & Raskoff Zeiss, 1972). Because the mind is the outcome of the brain, associations between its structure and activity and an individual’s intelligence have been investigated. For the purposes of this type of research, standardized tests are used as the measure of intelligence. Brain imaging studies demonstrate that standard measures of intelligence positively correlate with overall brain volume (Deary, Penke, & Johnson, 2010). More precisely, intelligence measures are positively correlated with the thickness of the cerebral cortex, particularly in the prefrontal cortex and temporal lobes. Because intelligence is such a broad concept, it is unlikely that we have intelligence centers in the brain. Instead, scientists have suggested that intelligent brains enjoy quick, efficient communication of information from one area to another along axon pathways (see Figure 10.17). This is particularly true of people with high levels of verbal intelligence, which is more closely related to the crystallized intelligence discussed earlier (Khundrakpam et al., 2017). Studies of people with brain damage indicate that fluid intelligence, but not crystallized intelligence, is negatively affected by damage to the frontal lobes. These observations are consistent with studies showing high levels of frontal lobe activity during diverse tests believed to demonstrate fluid intelligence (Gray & Thompson, 2004). Fluid intelligence abilities are highly correlated to working memory capacities (Khundrakpam et al., 2017). The relationships between brain structure and IQ scores are complex. The individual depicted with the blue line had the highest IQ score out of 100 participants, and in each area of the brain believed to correlate with IQ results, he showed much higher than average gray matter volume. Person 2 and Person 3 had identical scores on an IQ test, but their patterns of gray matter volume were quite different from each other. Further research might help psychologists better understand the relationships between observed differences in brain structure and intelligence. In response to research showing that students from the poorest schools in Shanghai outscored the children of doctors and lawyers in the United Kingdom on math tests, the British government flew 60 English-speaking Chinese teachers to London to provide advice about how to improve British math achievement. Chinese teachers recommended teaching to the brightest students in the class, while also ensuring the children with moderate or lower abilities were also served. Chinese teachers and students commonly express a belief that hard work is more important than natural ability in math achievement. According to Carol Dweck (Dweck, 2000), people believe one of two theories about their own intelligence. Some people believe in an entity theory that states that people have a certain fixed, unmodifiable amount of intelligence. Others believe in an incremental theory that states that intelligence is something you can improve through learning. This second approach does not deny that learning is easier for some people than for others but simply suggests that everyone can improve through effort. Students who believe in entity theory feel best when they complete easy, low-effort tasks and outperform other students. Challenges in the form of difficult tasks or higher performing peers threaten the self-esteem of the entity theorists. Dweck believes that the lavish praise heaped on today’s students promotes belief in the entity theory, resulting in anxiety about looking smart, avoidance of challenges, and an inability to cope with the inevitable educational setbacks. In contrast, incremental theorists like to stretch their skills and put their knowledge to use. They view easy tasks as a waste of time. These students are not as affected by setbacks and worries about looking smart as their entity theorist peers. Dweck’s two theories about intelligence parallel cultural differences regarding proficiency in math. In the United States, we tend to hold an entity theory of math ability—you have it or you don’t. People feel comfortable admitting that they are bad at math and view this as a good reason to stop taking math courses or working to improve. In East Asia, the incremental theory is dominant. Math is viewed as a difficult subject for most people that you must work to master. When Japanese and American students were randomly assigned to succeed or fail on a task by giving them either an easy or difficult task, the two groups responded very differently (Guglielmi & Brekke, 2017). The Americans who succeeded were more likely to persist on a follow-up task, view the tests as accurate, and rate the skills assessed by the task as important. This pattern was reversed for the Japanese students. The students who failed initially showed the same response as the Americans who had succeeded. As mentioned previously in this chapter, this difference in self-concept probably contributes to the superior achievement in math and science seen in East Asian students relative to their peers with different ethnicities. According to Dweck, educators who view self-esteem (see Chapter 12) as something you give to a student through the application of easy tasks, lavish praise, and avoidance of failure are making a big mistake. Instead, self-esteem could be viewed as something students give themselves. Educators can better promote student self-esteem by teaching students to value learning over the appearance of being smart, promoting the love of challenge and effort, and helping students view mistakes as stepping stones to mastery. Intelligence also seems to be related to the timing of brain development. As children approach puberty, the gray matter of the brain experiences a period of growth that slows down again later in adolescence. Children with average IQ scores showed a peak thickening of cortical gray matter around the age of 8, but children with superior IQ scores experienced a later peak, thickening around age 13 (Shaw et al., 2006). As we observed in Chapter 3, simple either–or thinking about nature and nurture is rarely correct when considering human behavior, including intelligence. The influences of heredity (nature) interact intimately with experience and other environmental factors (nurture) to produce a result. For example, infants who are breastfed have higher IQ scores than those who are not. However, the experience of being breastfed increases IQ results only in children with one variation of a gene; it has no effect on IQ results in children with another variation of the same gene (Caspi et al., 2007). A comparison of the amount of gray matter in the brains of identical and fraternal twins showed that the identical twins were more like each other than were fraternal twins, as indicated by red and yellow coloring, especially in areas where gray matter volume is correlated with IQ test results. (F is for frontal lobe and W indicates Wernicke’s area.)To recap the discussion in Chapter 3, heritability estimates how much of the variability in a characteristic observed in a population, such as variations in adult height, is because of genes. If genes play no role in this variation, such as the likelihood that people have tattoos, heritability is 0. When a condition is completely genetic, such as Huntington’s disease, heritability is 1.0. The heritability of adult intelligence as measured by IQ tests is usually reported to be about .75 (Neisser et al., 1996). When we say that the heritability of intelligence is .75, we are saying that 75% of the variance in intelligence observed in the population can be attributed to genetics, not that 75% of an individual’s intelligence is because of that person’s genes. As we observed in an earlier section, both overall brain size and proportion of gray matter are correlated with intelligence, and both are approximately 85% heritable, based on comparisons of identical and fraternal twins (Gray & Thompson, 2004). Although many genes are known to influence brain development, none have been conclusively linked to high IQ test performance. It is likely that a very large number of genes, each having a small impact and interacting with the individual’s environment, contribute to the development of intelligence. The fact that a trait demonstrates high heritability does not imply that change or improvement is impossible. A case in point is the highly heritable condition of phenylketonuria (PKU), in which a person cannot properly metabolize a particular amino acid found in many foods. Left unchecked, the condition leads to intellectual disability, discussed in a later section of this chapter. However, if a person with PKU is given an appropriate diet in which problem foods are avoided, intellectual development proceeds normally. The presence of data showing that IQ results are heritable does not mean we give up on anybody’s intellectual development. Worldwide increases in IQ scores of about 3 points per decade over the last 100 years illustrate the potential for change (Dickens & Flynn, 2006;  Dickens & Flynn, 2001). This increase in IQ scores, known as the Flynn effect, has occurred far too quickly to represent genetic changes (see Figure 10.18). Improvements in nutrition and other health factors probably account for some of the change. Using information from the World Health Organization, researchers have identified strong correlations between a nation’s freedom from serious infectious diseases and its citizens’ average IQ scores (Eppig, Fincher, & Thornhill, 2010). As nations become wealthier and more capable of battling disease, their citizens’ IQ scores increase. Surprisingly, the test score gains are most pronounced in supposed culture-free tests such as the Raven’s Progressive Matrices (Fox & Mitchum, 2013). Participants born after 1990 scored far better on these tests than did participants born in 1940. This change might reflect an improvement in the ability to manage dissimilar items that accompanies living in a modern society. IQ test results have been gradually increasing, although the exact causes for these changes are not completely understood. Improvements in nutrition, health care, and education are likely reasons for much of the increase. Matrix reasoning tests, containing items like the one in Figure 10.15, show the largest gains. Psychologists have produced long lists of environmental factors that influence intellectual development, including nutrition and exposure to mentally stimulating activities. Most of these environmental advantages are not cheap. Consequently, it is not surprising to find that socioeconomic status, a measure of family income, education, and other class factors, is positively correlated with IQ score (Turkheimer, Haley, Waldron, D’Onofrio, & Gottesman, 2003). This correlation does not tell us whether more intelligent people enjoy higher socioeconomic status, whether higher socioeconomic status provides means to optimize intelligence, whether some unknown third factor produces both high intelligence and high socioeconomic status, or whether some combination of these factors occurs. Nonetheless, poverty continues to be a significant risk for a low IQ score. We have been discussing the concept of a general intelligence that characterizes an individual, but is it possible for the same sort of measure to describe the abilities of groups of people? Such a measure might be quite useful to organizations using teams. The Question: Do groups of people have a collective intelligence that predicts their performance, and if so, what factors contribute to a group’s collective intelligence? Nearly 700 people completed individual intelligence tests and then were randomly assigned to work groups of two to five individuals (Woolley, Chabris, Pentland, Hashmi, & Malone, 2010). Each group was assigned several tasks to complete that varied in the amount of coordinated activity required for success, including solving visual puzzles, brainstorming, making collective moral judgments, and negotiating the allocation of limited resources. Some groups finished their session by playing checkers against a computerized opponent, while others completed an architectural design task. Additional measures were taken of factors believed to be related to group performance, including motivation, satisfaction, group cohesion, social sensitivity, and distribution of speaking turns. This research does not pose any unusual ethical dilemmas. Routine protections of informed consent and confidentiality should be sufficient. Evidence for a group or collective intelligence did emerge. For each group, performance across the different tasks was highly and positively correlated. Further statistical analyses ruled out the average individual intelligence of the group or the maximum individual intelligence of individuals in the group as significant predictors of group performance, leaving collective intelligence as a single, strong predictor of group performance (see Figure 10.19). A group’s performance on a variety of tasks, from playing video games to constructing a complex architectural design, was predicted better by the group’s collective intelligence than by the average intelligence of the group’s members or by the highest IQ score among the group’s members. Surprisingly, typical group features such as motivation, satisfaction, or group cohesion failed to predict group performance. Individual features, such as the individual intelligence of the members, also failed to predict group performance. Instead, the members’ scores on the social sensitivity instrument, called the Reading the Mind in the Eyes test, and how evenly speaking turns were distributed had a large impact on the group’s collective intelligence. You might have had opportunities to observe collective intelligence while working on group projects. This research shows that bringing together the most intelligent people might not guarantee the best results. Instead, groups of people who are more empathic and do not dominate the conversation might have the greatest success. Assuming that IQ scores are normally distributed, with an average of 100 and a standard deviation of 15, about 68% of the population should fall within one standard deviation (85–115), and 95% of the population should fall within two standard deviations (70–130). The remaining 5% is divided between the two tails of the distribution, either above 130 or below 70 (see Figure 10.20). IQ test results form an approximately normal distribution, which means that about 68% of the population falls between IQ scores of 85 and 115. Ninety-five percent of the population falls between IQ scores of 70 and 130, with the remaining 5% divided between the two tails. According to the Diagnostic and Statistical Manual of Mental Disorders (DSM-5; APA, 2013; see Chapter 14), intellectual disabilityintellectual disabilityA condition diagnosed in individuals with IQ scores below 70 and poor adaptive behaviors; also known as mental retardation.            intellectual disability        A condition diagnosed in individuals with IQ scores below 70 and poor adaptive behaviors; also known as mental retardation.             or intellectual developmental disorder is diagnosed in individuals who show deficits in intellectual functioning beginning early in childhood, accompanied by deficits in independent living skills. Although individually administered standardized IQ tests are often used as a starting point when evaluating an individual who might have an intellectual disability, the clinician’s impressions can be used to make the decision, too. Approximately 1 to 3% of the population will score 70 ± 5 or below on a standardized IQ test (Szymanski & King, 1999). In addition to an IQ score in this range, individuals with intellectual disability demonstrate problems with adaptive behaviors or life skills. These behaviors might include the ability to balance a checkbook, receive correct change from a cashier, read a bus schedule, buy groceries, maintain personal hygiene, and other skills required for independent living. Intellectual disability is divided into categories of mild, moderate, severe, and profound based on IQ scores and level of adaptive functioning (APA, 2013). Mild intellectual disability is typically accompanied by IQ scores of 55 to 70, or between two and three standard deviations from the mean of 100. With proper intervention, individuals in this group are able to master a sixth-grade curriculum, although it will take them until age 18 to do so. Most individuals in this group can live independently, and many work, marry, and have families. Mild intellectual disability is typically not the result of genetic or medical problems (Zigler, 1967;  Zigler & Hodapp, 1986). As a result, mild intellectual disability is frequently called familial retardation, recognizing that it usually results from preventable, environmental causes. Poverty is an obvious risk factor for this condition because poor parents may be unable to obtain the health care, diet, and other environmental benefits needed to produce healthy children (see Figure 10.21). Mild forms of intellectual disability, leading to IQ scores between 55 and 70, are also known as familial retardation because these cases are not due to medical or genetic problems. Poverty is a large risk factor for this level of intellectual disability. A little more than 5 in 1,000 children living above the poverty line have intellectual disability, but this number jumps to 9 in 1,000 among children living below the poverty line. IQ scores between 40 and 55, or between three and four standard deviations from the mean, indicate moderate intellectual disability. Unlike mild cases, moderate intellectual disability typically results from genetic or medical conditions rather than familial factors. Genetic conditions such as Down syndrome are likely to produce disability in this range. The academic attainment of most individuals in this category is limited to the second-grade curriculum, and again, most do not achieve this level until about the age of 18 years. Most of these individuals need some type of assisted living, although the type and extent of needed services vary widely among affected individuals. Severe intellectual disability is diagnosed in individuals with IQ scores between 25 and 40, or four to five standard deviations below the mean, while profound intellectual disability is diagnosed in individuals with IQ scores below 25. Both severe and profound intellectual disabilities generally result from serious medical conditions and are identified at birth or early in infancy. Individuals with severe intellectual disability can learn a few high-priority words, such as stop or hot. Individuals with profound intellectual disability can learn some basic self-care skills, such as feeding themselves or washing their hands. Depending on the nature of the medical problems, these individuals can require significant assistance and supervision. Individuals with intellectual disability face several common problems. Many children with intellectual disability form insecure attachments with their caregivers, described in detail in Chapter 11 (Clegg & Sheard, 2002). Ideally, children form a secure attachment characterized by demonstrating a clear preference for a caregiver over strangers, protesting when the caregiver leaves, and indicating a willingness to explore their environment (Ainsworth & Bowlby, 1965). Australian model and fashion designer Madeline Stuart has Down syndrome. Language skills are affected depending on the severity of the intellectual disability (Chapman, 1995). Children with intellectual disability have problems expressing themselves clearly, although they may understand a great deal that is said to them. In conjunction with typically poor social skills, these language deficits may result in peer rejection. Consequently, successful intervention programs address language and social skills, in addition to academic and life skill work. Between 10 and 40% of individuals with intellectual disability experience some type of emotional or behavioral disorder (McGaw, Shaw, & Beckley, 2007). Anxiety, impulsiveness, and mood disorders are the most common disorders seen in this population. When intellectual disability is more severe, individuals may engage in pica, or the eating of nonedibles, or self-injurious behaviors, such as banging the head against the floor or wall. Individuals with intellectual giftedness, who make up approximately 1 to 3% of the population, score two or more standard deviations above the mean, or more than 130 on a standardized IQ test. Genius combines high intelligence with creativity and achievement (Renzulli & Delcourt, 1986). Having a high IQ score provides advantages in many aspects of life. One of the longest running studies in psychology is a longitudinal examination of gifted children initiated in 1921 (Terman, 1925;  Terman & Oden, 1959). The original participants were children selected because of their very high IQ scores, averaging 150. The gifted participants not only maintained their high IQ scores but also enjoyed better physical health, emotional stability, occupational attainment, and social satisfaction throughout their adult lives. Despite advice from the American Academy of Pediatrics telling parents that children under the age of 2 should have zero screen time (television, tablets, phones, or computers), the market for electronic media designed to make babies smarter is booming (Committee on Public Education, 2001). Sporting names like Baby Einstein, Brainy Baby, and Baby Genius, these materials make their intent clear to consumers. The popularity of these programs indicates that today’s parents take the need for nurture seriously. Little scientific research has been done on the use of these products with very young children. One study found that watching baby videos actually had a detrimental effect on young children’s language acquisition. Infants younger than 16 months and exposed to the videos understood from six to eight fewer words for each hour of exposure compared to nonexposed infants (Frederick, Dimitri, & Andrew, 2007). This should not be surprising, given other research that emphasizes the social nature of language learning discussed in this chapter, such as the study showing that young children learn language from a speaker in the room, but not from the same speaker being televised. Rather than investing in baby videos, we hope that parents can sit back, relax, play with, and enjoy their children, who grow up all too quickly. Despite advice from the American Academy of Pediatrics to avoid screen time for children under the age of 2 years, there is a booming market for apps and DVDs advertising their ability to make children smarter. High intellect, particularly as measured by an IQ score, does not capture completely what we mean by genius. Despite their successes, the gifted participants in the longitudinal study just cited did not produce genius work. Nor do all remarkable thinkers possess particularly high IQ scores. Nobel laureate Richard Feynman was disappointed to learn that his IQ score was only 124 (Gleick, 1992). These teens, standing with former astronaut and NASA administrator Charles Bolden, are not satisfied by finding the right answer to teachers’ questions. Instead, they tackled tough problems to compete in the White House Science Fair. Like individuals on the lower extreme of IQ scores, children with high IQ scores benefit from educational opportunities tailored to their abilities. Unfortunately, the structure of public education in the United States, with its emphasis on grade levels based on age, rarely provides optimum learning for gifted children. A report by the U. S. Department of Education noted that children with IQ scores of 140 or above typically know at least half of a grade’s curriculum before the school year even begins, and those with IQ scores of 170 or above know virtually all of it (U. S. Department of Education Office of Educational Research and Improvement, 1993). Their time in school is subsequently wasted, and the material is so easy that it encourages poor learning habits ill-suited to later educational challenges. Educators are returning to ability groupings and acceleration to resolve these problems. These practices benefit not only the more gifted students, but they also provide benefits for average and below-average students, although equitable assignment to groups remains a concern (Steenbergen-Hu, Makel, & Olszewski-Kubilius, 2016). Classic research suggests that some people are maximizers, who strive to reach the best outcome. Satisficers are more willing to choose outcomes that are merely acceptable (Simon, 1957). Maximizers are perfectionists who evaluate all choices before settling on one, so they do not make quick decisions. Because maximizers feel more regret when a decision doesn’t work out well, they tend to avoid making decisions. Although they may experience better outcomes than satisficers on many occasions, maximizers might still feel worse. Satisficers are more likely to see their glass of life as half full, whereas maximizers are more likely to see their glass as half empty. What does this distinction mean for interpersonal relationships? Finding a romantic partner and making a long-term commitment to that person involve some important decisions. Romance is consistently ranked among the top regrets in life for most people (Roese & Summerville, 2005). These facts suggest that maximizers might experience obstacles within the realm of relationships. Either they will let opportunities pass by because they are still looking for that perfect person, or they will avoid making a commitment for fear of regretting it later. Their perfectionist standards might make it impossible for them to appreciate a partner who is a good match, perhaps because that person does not look like a supermodel or squeezes the toothpaste tube the wrong way. Faced with a large array of choices, satisficers will pick one that works, but maximizers will evaluate all the options to find the perfect choice. We’re guessing that most of these candies taste good. Does this mean maximizers are doomed in relationships? Not at all. Recognizing that our automatic ways of behaving will not always lead us to our goals can help us identify areas where we need to take conscious, systematic control. Many maximizers blame their partners for a failed romance (the partner just didn’t measure up) instead of taking a hard look at their own contributions to the relationship. If you know your maximizing tendencies are leading you in the wrong directions, you can use the steps to effective problem solving outlined earlier in this chapter to supply alternatives that might work better. If Psychologists are to be able to inform policy makers about ways to discourage cyberbullying, it would be helpful to be able to predict the individuals who are most likely to engage in this behavior. Looking at the category of cyberbullies, we can see how using exemplars and prototypes might help us predict the features of cyberbullies. Perhaps you have a personal acquaintance who is known to be a cyberbully. This might be your exemplar. You might also consider a prototypical or average cyberbully based on your personal experience and what you have heard from others or read. Take a moment and write down a list of what you think might be the key features that define the category of cyberbully. Now let’s see what psychological science has to say, and you’ll be able to see where the features of your category agree or disagree with the scientific literature. Did you make a conclusion about gender? Prior research has shown that girls are less likely to participate in traditional bullying, but their role in cyberbullying remains unclear. Researchers have reported that slightly more males than females engage in cyberbullying (Aricak et al., 2008;  Li, 2006;  Slonje & Smith, 2008), more females than males engage in cyberbullying (Kowalski & Limber, 2013), or that there are no significant gender differences in perpetrators of cyberbullying (Hinduja & Patchin, 2008). Given these mixed results, we might assume that gender is not a very helpful feature in establishing a cyberbully profile. Age might be a useful dimension for our concept of cyberbully. Is there a particular age range where this behavior is more common? If you guessed that cyberbullying peaks around age 14, then you are correct (Cook, Williams, Guerra, & Tuthill, 2007). Knowing this could be very helpful. You would not want to plan an educational program to be administered to students who are past this peak age group, thereby missing the main targets of your interventions. Some other characteristics of cyberbullies are intuitive. Cyberbullies are more expert in their use of the internet than their noncyberbullying peers, and they experience less parental supervision (Vandebosch & Van Cleemput, 2009). As we have seen in other situations, however, intuitive conclusions are not always consistent with scientific facts. You might have a prototype or exemplar cyberbully in mind who is socially awkward and more likely to be a victim of traditional bullying than to be a perpetrator. Facts show that cyberbullies are actually more socially competent than their peers, not less, and they are about equally likely to engage in traditional bullying as they are in cyberbullying (Vandebosch & Van Cleemput, 2009). Widely held stereotypes about who is more likely to cyberbully are not always supported by scientific research. How did you do? Did you find a need to adjust the characteristics of your cyberbully concept in light of the scientific evidence? If so, that is part of education. We are constantly revising our concepts in light of new information. Type of intelligenceDescriptionExampleGeneral intelligence (g)A single measure of an individual’s intellectual ability that predicts most of that person’s intellectual performance. Verbal, mathematical, spatial, and logical skills showing high positive correlations within an individual. Fluid intelligenceA type of general intelligence that allows logical thinking without needi.ng learned knowledgeRecognizing relationships between geometric shapes. Crystallized intelligenceA type of general intelligence that requires learned knowledge. Using your knowledge of the multiplication tables to figure out interest on a new car loan. Multiple intelligencesSingle skills that tend to show relatively low correlations with one another and with general intelligence. Strong musical abilities in people with Williams syndrome, which results in a lower than normal IQ score. Emotional and social intelligenceThe ability to manage emotions and reason about other people’s states of mind. Managing anger appropriately and showing empathy for others. Collective intelligenceA quality of group process independent of individual group members’ intelligence that predicts group performance. A team featuring good social sensitivity and conversation sharing that completes a task successfully. `;
